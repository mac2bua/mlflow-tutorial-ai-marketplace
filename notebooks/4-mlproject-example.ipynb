{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FILL IN YOUR NAME\n",
    "NAME = \"example\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running MLprojects\n",
    "\n",
    "Any local directory or Git repository can be treated as an MLflow project. Let's run [an example project](https://github.com/mlflow/mlflow-example) from the official MLflow github repository.\n",
    "\n",
    "There are two ways to run the project:\n",
    "\n",
    "- Using the CLI: `mlflow run `\n",
    "- Using the Python API: `mlflow.projects.run()`\n",
    "\n",
    "For this example, we will use the Python API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "project_uri = \"https://github.com/mlflow/mlflow-example\"\n",
    "params = {\"alpha\": 0.5, \"l1_ratio\": 0.01}\n",
    "\n",
    "# Run MLflow project and create a reproducible conda environment\n",
    "submitted_run = mlflow.run(project_uri, parameters=params, use_conda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submitted_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submitted_run.run_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving Run Details\n",
    "\n",
    "Using the `submitted_run` object we can retrieve the details from the run that we just submitted. In order to do so, we will use the [Python API](https://www.mlflow.org/docs/latest/python_api/mlflow.tracking.html). In particular, we are interested in retrieving the path to the artifacts because this will be useful for us later. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "# retrive the run by using the MLflow client\n",
    "client = MlflowClient()\n",
    "run = client.get_run(submitted_run.run_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the info about the run\n",
    "run.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the run's artifacts path\n",
    "run.info.artifact_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What we just learned?\n",
    "\n",
    "* It is possible to run projects easily by using the Python API.\n",
    "* Projects can be stored as local folders or Git repositories.\n",
    "* After running a project we can use the `mlflow.tracking` module to retrieve all the information about the run.\n",
    "\n",
    "This will useful for the next exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining ML pipelines with MLflow\n",
    "\n",
    "\n",
    "MLflow allows us to chain together multiple different runs. Each run, encapsulates a transformation or training step. For this exercise, we will run the following ML pipeline using the MLproject module:\n",
    "\n",
    "![multistep-workflow](https://github.com/mlflow/mlflow/raw/master/docs/source/_static/images/tutorial-multistep-workflow.png?raw=true)\n",
    "\n",
    "There are four entry points that make up the pipeline:\n",
    "\n",
    "* **load_raw_data.py**: Downloads the MovieLens dataset (a set of triples of user id, movie id, and rating) as a CSV and puts it into the artifact store.\n",
    "* **etl_data.py**: Converts the MovieLens CSV from the previous step into Parquet, dropping unnecessary columns along the way. This reduces the input size from 500 MB to 49 MB, and allows columnar access of the data.\n",
    "* **als.py**: Runs Alternating Least Squares for collaborative filtering on the Parquet version of MovieLens to estimate the movieFactors and userFactors. This produces a relatively accurate estimator.\n",
    "* **train_keras.py**: Trains a neural network on the original data, supplemented by the ALS movie/userFactors -- we hope this can improve upon the ALS estimations.\n",
    "\n",
    "### Example: multi-step workflow\n",
    "\n",
    "While we can run each of these steps manually, here we have a **driver run**, defined as the method `mlflow_pipeline` below. This method will run the steps in order, passing the results of one step to the next. \n",
    "\n",
    "We will provide you with an auxiliary method that given an entry point and some parameters launch a run using the MLflow's Python API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _run(entrypoint: str, parameters: dict, project_dir: str = '../mlflow-project/'):\n",
    "    \"\"\"Launches an entry point by providing the given parameters.\"\"\"\n",
    "    \n",
    "    print(\"Launching new run for entrypoint=%s and parameters=%s\" % (entrypoint, parameters))\n",
    "    submitted_run = mlflow.run(project_dir, \n",
    "                               entrypoint, \n",
    "                               parameters=parameters,\n",
    "                               use_conda=False,\n",
    "                               storage_dir=\"../../data/\")\n",
    "    \n",
    "    client = mlflow.tracking.MlflowClient()\n",
    "    return client.get_run(submitted_run.run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are some tips in case you want to implement the code on your own:\n",
    "\n",
    "* You can use the provided method `_run` to execute each step of the pipeline\n",
    "* Make sure your are passing the correct values for `entrypoint` and `parameters`.\n",
    "* The entrypoint names and input parameters are defined in MLproject file located in the folder `mlflow-project` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "# set experiment\n",
    "experiment_name = f\"pipeline-{NAME}\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "def mlflow_pipeline(als_max_iter, keras_hidden_units, max_row_limit):\n",
    "    \n",
    "    with mlflow.start_run() as active_run:\n",
    "        os.environ[\"SPARK_CONF_DIR\"] = os.path.abspath(\".\")\n",
    "    \n",
    "        load_raw_data_run = _run(\"load_raw_data\", {})\n",
    "        ratings_csv_uri = os.path.join(load_raw_data_run.info.artifact_uri, \"ratings-csv-dir\")\n",
    "\n",
    "        etl_data_run = _run(\"etl_data\", {\"ratings_csv\": ratings_csv_uri, \"max_row_limit\": max_row_limit})\n",
    "        ratings_parquet_uri = os.path.join(etl_data_run.info.artifact_uri, \"ratings-parquet-dir\")\n",
    "\n",
    "        als_run = _run(\"als\", {\"ratings_data\": ratings_parquet_uri, \"max_iter\": str(als_max_iter)})\n",
    "        als_model_uri = os.path.join(als_run.info.artifact_uri, \"als-model\")\n",
    "\n",
    "        keras_params = {\n",
    "            \"ratings_data\": ratings_parquet_uri, \n",
    "            \"als_model_uri\": als_model_uri, \n",
    "            \"hidden_units\": keras_hidden_units\n",
    "        }\n",
    "        train_keras_run = _run(\"train_keras\", keras_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After completing the code, run the next cell and go to the MLflow UI to check the results :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# once you finished with the method `mlflow_pipeline` run this line!\n",
    "mlflow_pipeline(als_max_iter=10, keras_hidden_units=20, max_row_limit=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
