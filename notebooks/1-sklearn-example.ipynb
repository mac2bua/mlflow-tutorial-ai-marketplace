{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FILL IN YOUR NAME\n",
    "NAME = \"example\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from urllib.parse import urlparse\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "import logging\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "logging.basicConfig(level=logging.WARN)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset\n",
    "\n",
    "We will use an example from the official documentation of MLflow. The goal is to model wine quality based on physicochemical tests (see more [here](http://www3.dsi.uminho.pt/pcortez/wine/)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(40)\n",
    "\n",
    "# Read the wine-quality csv file from the URL\n",
    "csv_url = (\n",
    "    \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\"\n",
    ")\n",
    "try:\n",
    "    data = pd.read_csv(csv_url, sep=\";\")\n",
    "except Exception as e:\n",
    "    logger.exception(\n",
    "        \"Unable to download training & test CSV, check your internet connection. Error: %s\", e\n",
    "    )\n",
    "\n",
    "# Split the data into training and test sets. (0.75, 0.25) split.\n",
    "train_data, test_data = train_test_split(data)\n",
    "\n",
    "# The predicted column is \"quality\" which is a scalar from [3, 9]\n",
    "train_x = train_data.drop([\"quality\"], axis=1)\n",
    "test_x = test_data.drop([\"quality\"], axis=1)\n",
    "train_y = train_data[[\"quality\"]]\n",
    "test_y = test_data[[\"quality\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We will define a simple method to train the model. This method takes as inputs two of the hyperparameters of the model, namely `alpha` and `l1_ratio`. These parameters control the regularization of the model, so they will affect the complexity and the generalization power of the model (more [details](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html)). \n",
    "\n",
    "*Disclaimer: we will use the test set to evaluate multiple times the performance of the model while changing its hyperparameters. This is not a good practice and we are doing it here just for the sake of simplicity.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(alpha=0.5, l1_ratio=0.5):\n",
    "    \"\"\"Train an ElasticNet on the Wine Quality Dataset.\"\"\"\n",
    "\n",
    "    # train model\n",
    "    lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "    lr.fit(train_x, train_y)\n",
    "\n",
    "    # make predictions\n",
    "    predicted_qualities = lr.predict(test_x)\n",
    "\n",
    "    def eval_metrics(actual, pred):\n",
    "        rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "        mae = mean_absolute_error(actual, pred)\n",
    "        r2 = r2_score(actual, pred)\n",
    "        return rmse, mae, r2\n",
    "    \n",
    "    # evaluate trained model\n",
    "    (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "    print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "    print(\"  RMSE: %s\" % rmse)\n",
    "    print(\"  MAE: %s\" % mae)\n",
    "    print(\"  R2: %s\" % r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train and evaluate the model by just calling the method `train`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the `r2` is quite low, let's if we can improve it by playing a bit with the hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(0.001, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(0.00001, 0.00001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we have found a better performance by playing a bit with the hyperparameter :)\n",
    "\n",
    "On the other hand, printing the performance on the stdout doesn't seem like the best solution to track the progress. Let's see what can we do by using MLflow tracking module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking Experiments with MLflow\n",
    "\n",
    "Next, let's check how much effort it will take to use the MLflow Tracking module in order to keep track of our experiments. The method `train_mlflow` below trains and evaluates an ElasticNet model in exactly the same way we did with the method `train` but it also sends the run details to MLflow so we can later visualize them.\n",
    "\n",
    "Here are a few tips in case you want to try writing the method `train_mlflow` on your own:\n",
    "* Check the **template** below (we already imported the libraries and set the experiment name for you)\n",
    "* You can copy and pase the code in the method `train` above and then add the MLflow logging.\n",
    "* You should log parameters (like `alpha` and `l1_ratio`), metrics (`rmse`, `mae`, etc.), the model and optionally some tags and artifacts of your choice.\n",
    "* Check the [official documentation](https://www.mlflow.org/docs/latest/index.html) for more information.\n",
    "\n",
    "### Template\n",
    "\n",
    "<img src=\"experiment_tracking_template.png\" alt=\"Drawing\" style=\"width: 600px;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure experiment\n",
    "experiment_name = f\"sklearn-{NAME}\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "def train_mlflow(alpha=0.5, l1_ratio=0.5):\n",
    "    \"\"\"Train an ElasticNet on the Wine Quality Dataset and Log Experiment to MLflow.\"\"\"\n",
    "\n",
    "    # Train model\n",
    "    lr = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "    lr.fit(train_x, train_y)\n",
    "\n",
    "    # Make predictions\n",
    "    predicted_qualities = lr.predict(test_x)\n",
    "\n",
    "    def eval_metrics(actual, pred):\n",
    "        rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "        mae = mean_absolute_error(actual, pred)\n",
    "        r2 = r2_score(actual, pred)\n",
    "        return rmse, mae, r2\n",
    "    \n",
    "    # Evaluate trained model\n",
    "    (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "    print(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "    print(\"  RMSE: %s\" % rmse)\n",
    "    print(\"  MAE: %s\" % mae)\n",
    "    print(\"  R2: %s\" % r2)\n",
    "    \n",
    "    \n",
    "    # MLflow logging\n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        # Add tags to the run\n",
    "        mlflow.set_tag('developer', 'cristian')\n",
    "        \n",
    "        # Log params\n",
    "        mlflow.log_params({\n",
    "            'alpha': alpha,\n",
    "            'l1-ratio': l1_ratio\n",
    "        })\n",
    "        \n",
    "        # Log metrics\n",
    "        mlflow.log_metrics({\n",
    "            'rmse': rmse,\n",
    "            'mae': mae,\n",
    "            'r2': r2\n",
    "        })\n",
    "        \n",
    "        # Log model\n",
    "        mlflow.sklearn.log_model(lr, artifact_path='model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mlflow(0.1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mlflow(0.5, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mlflow(0.1, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for alpha in np.logspace(-10, -1, 5):\n",
    "    for l1_ratio in np.logspace(-10, -1, 5):\n",
    "        train_mlflow(alpha, l1_ratio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (MLflow)",
   "language": "python",
   "name": "mlflow-workshop-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
