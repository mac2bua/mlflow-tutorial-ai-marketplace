{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import boto3\n",
    "import json\n",
    "import os\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sagemaker as mfs\n",
    "from mlflow.entities import ViewType\n",
    "from mlflow.tracking import MlflowClient\n",
    "\n",
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Register a model\n",
    "\n",
    "Let's use the MLflowClient object to retrieve the id of the best run for the experiment number 1, and register the model to the MLflow model registry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best run from experiment ID 1 by r2 score\n",
    "run = MlflowClient().search_runs(\n",
    "  experiment_ids=\"1\",\n",
    "  filter_string=\"\",\n",
    "  run_view_type=ViewType.ALL,\n",
    "  max_results=1,\n",
    "  order_by=[\"metrics.r2 DESC\"]\n",
    ")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To register a model we just need to pass the path to the model and the name of the registered model. If the name doesn't exist, MLflow will create a new one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = mlflow.register_model(\n",
    "    f\"runs:/{run.info.run_id}/model\",\n",
    "    \"wine-quality-predictor\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List registered models\n",
    "\n",
    "The following method prints the list of registered models and the latests versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "client = MlflowClient()\n",
    "\n",
    "def print_model_info(models):\n",
    "    \"\"\"Lists models registered in MLflow's Model Registry.\"\"\"\n",
    "    \n",
    "    for m in models:\n",
    "        print(\"name: {}\".format(m.name))\n",
    "        for mv in sorted(m.latest_versions, key=lambda x: x.version):\n",
    "            print(\n",
    "                \"\\tversion: {}, registration date: {}, stage: {}\"\n",
    "                .format(mv.version, \n",
    "                        datetime.fromtimestamp(mv.creation_timestamp/1000.0), \n",
    "                        mv.current_stage)\n",
    "            )\n",
    "        print(\"--\")\n",
    "\n",
    "print_model_info(client.list_registered_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transitioning an MLflow model's stage\n",
    "\n",
    "We can also use the MLflowClient object to transition registered models between stages and add annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_stage = \"Production\"\n",
    "\n",
    "client.transition_model_version_stage(\n",
    "    name=\"wine-quality-predictor\",\n",
    "    version=1,\n",
    "    stage=new_stage\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.update_model_version(\n",
    "    name=\"wine-quality-predictor\",\n",
    "    version=1,\n",
    "    description=f\"{new_stage} model since {datetime.today().date()}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_model_info(client.list_registered_models())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serve model locally \n",
    "\n",
    "MLflow also has a CLI that supports the following commands:\n",
    "\n",
    "* `serve` deploys the model as a local REST API server.\n",
    "\n",
    "* `build_docker` packages a REST API endpoint serving the model as a docker image.\n",
    "\n",
    "* `predict` uses the model to generate a prediction for a local CSV or JSON file. Note that this method only supports DataFrame input.\n",
    "\n",
    "We will deploy the latest production model as a local REST API server. To do so, we just need to run these command in a terminal:\n",
    "\n",
    "* `source .env`\n",
    "* `mlflow models serve -m models:/wine-quality-predictor/Production --no-conda`\n",
    "\n",
    "Then from another terminal, run this to send a prediction request to the server:\n",
    "\n",
    "`curl http://127.0.0.1:5000/invocations -H 'Content-Type: application/json' -d '{\"columns\":[\"fixed acidity\",\"volatile acidity\",\"citric acid\",\"residual sugar\",\"chlorides\",\"free sulfur dioxide\",\"total sulfur dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\"],\"index\":[82],\"data\":[[7.4,0.5,0.47,2.0,0.086,21.0,73.0,0.997,3.36,0.57,9.1]]}'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy model in AWS Sagemaker\n",
    "\n",
    "**ATENTION**: *in order to deploy the model to SageMaker you will need to provide a valid execution role ARN and the image URL. These details need to be added to the .env file.*\n",
    "\n",
    "\n",
    "The `mlflow.sagemaker` module can deploy `python_function` models locally in a Docker container with SageMaker compatible environment and remotely on SageMaker. \n",
    "\n",
    "Usage:\n",
    "\n",
    "* `mlflow sagemaker build-and-push-container`  - build the container (only needs to be called once)\n",
    "* `mlflow sagemaker run-local -m <path-to-model>`  - test the model locally\n",
    "* `mlflow sagemaker deploy <parameters>` - deploy the model remotely\n",
    "\n",
    "Using the following code you can deploy the model to SageMaker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deployment configuration\n",
    "region = os.environ.get(\"AWS_DEFAULT_REGION\")\n",
    "aws_id = os.environ.get(\"AWS_ID\")\n",
    "arn = os.environ.get(\"AWS_ARN\")\n",
    "app_name = \"mlflow-example\"\n",
    "model_uri = \"models:/wine-quality-predictor/Production\"\n",
    "image_url = aws_id + \".dkr.ecr.\" + region + \".amazonaws.com/mlflow-pyfunc:1.14.1\"\n",
    "\n",
    "if aws_id and arn:\n",
    "    mfs.deploy(app_name=app_name, \n",
    "               model_uri=model_uri, \n",
    "               region_name=region, \n",
    "               mode=\"create\",\n",
    "               execution_role_arn=arn,\n",
    "               image_url=image_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Calling the Inference Endpoint\n",
    "\n",
    "Let's use the inference endpoint provided by Sagemaker to make predictions, we are providing two utility methods to interact with it:\n",
    "\n",
    "- check_status: checks the status of our endpoint.\n",
    "- query_endpoint: sends an inference request to the inference endpoint and returns the predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_status(app_name, region):\n",
    "    sage_client = boto3.client('sagemaker', region_name=region)\n",
    "    endpoint_description = sage_client.describe_endpoint(EndpointName=app_name)\n",
    "    endpoint_status = endpoint_description[\"EndpointStatus\"]\n",
    "    return endpoint_status\n",
    "\n",
    "if aws_id and arn:\n",
    "    print(\"Application status is: {}\".format(check_status(app_name, region)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_endpoint(app_name, input_json):\n",
    "    client = boto3.session.Session().client(\"sagemaker-runtime\", region)\n",
    "\n",
    "    response = client.invoke_endpoint(\n",
    "        EndpointName=app_name,\n",
    "        Body=input_json,\n",
    "        ContentType='application/json; format=pandas-split',\n",
    "    )\n",
    "    preds = response['Body'].read().decode(\"ascii\")\n",
    "    preds = json.loads(preds)\n",
    "    print(\"Received response: {}\".format(preds))\n",
    "    return preds\n",
    "\n",
    "if aws_id and arn:\n",
    "    query_input = '{\"columns\":[\"fixed acidity\",\"volatile acidity\",\"citric acid\",\"residual sugar\",\"chlorides\",\"free sulfur dioxide\",\"total sulfur dioxide\",\"density\",\"pH\",\"sulphates\",\"alcohol\"],\"index\":[82],\"data\":[[7.4,0.5,0.47,2.0,0.086,21.0,73.0,0.997,3.36,0.57,9.1]]}'\n",
    "    prediction1 = query_endpoint(app_name=app_name, input_json=query_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (MLflow)",
   "language": "python",
   "name": "mlflow-workshop-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
